{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 熵\n",
    "\n",
    "Entropy:度量事物的不确定性，不确定性越高，熵就越大，反之越确定，熵越小；\n",
    "\n",
    "随机事件(多类别)的熵可以表示为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "entropy = -p_1log_2{(p1)} - p_2log_2(p2) - ... - p_nlog_2(p_n) = -\\sum_{i=1}^n p_ilog_2(p_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 信息增益：\n",
    "\n",
    "父结点的熵与子结点上的平均值之间的差值；\n",
    "\n",
    "![](./dt001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树算法原理：\n",
    "\n",
    "**信息增益最大化**: 每步决策都选择信息增益最大的特征，作为当前分类特征依据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11260735516748954\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def two_group_ent(first, tot):                        \n",
    "    return -(first/tot*np.log2(first/tot) + (tot-first)/tot*np.log2((tot-first)/tot))\n",
    "\n",
    "tot_ent = two_group_ent(10, 24)                       \n",
    "g_feature_17_ent = 15/24 * two_group_ent(11,15) + 9/24 * two_group_ent(6,9)                  \n",
    "\n",
    "answer = tot_ent - g17_ent  \n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树的超参数\n",
    "\n",
    "为了创建泛化能力好的决策树，我们可以调优决策树的多个方面。我们把决策树的这些可调优的多个方面称为“超参数”。以下是决策树中使用的一些最重要的超参数。\n",
    "\n",
    "## 最大深度\n",
    "决策树的最大深度就是从根到叶之间可能的最大长度。一个最大深度为 k 的决策树最多有$2^k$ 个叶子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最少样本分割数\n",
    "\n",
    "一个节点必须至少有min_samples_split个样本才能足够大以进行拆分。如果一个节点的样本数少于 min_samples_split 个， 则分割过程停止，该节点不会被分割。\n",
    "![](./dt002.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然而 min_samples_split 不会控制叶的最小尺寸。正如你在上面右边的示例中看到的，父节点有20个样本，大于min_samples_split = 11，因此这个节点被拆分。但在此节点被拆分后，有一个子节点的样本数为5，小于min_samples_split = 11。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 每片叶子的最小样本数\n",
    "\n",
    "当分割一个节点时，可能会遇到的一个问题是分割不均匀，例如某个子节点有99个样本，另一个子节点可能只有1个样本。这会影响决策树的生成，也浪费计算资源和时间。为避免这种情况，我们可以为每个叶子上允许的样本数设置一个最小值。\n",
    "\n",
    "## 每次分裂的最小样本数\n",
    "\n",
    "这个参数与每片叶子上的最小样本树相同，只不过是应用在节点的分裂当中。\n",
    "\n",
    "\n",
    "## 最大特征数\n",
    "有时，我们会遇到特征数量过于庞大，而无法建立决策树的情况。在这种状况下，对于每一个分裂，我们都需要检查整个数据集中的每一个特征。这种过程极为繁琐。而解决方案之一是限制每个分裂中查找的特征数。如果这个数字足够庞大，我们很有可能在查找的特征中找到良好特征（尽管也许并不是完美特征）。然而，如果这个数字小于特征数，这将极大加快我们的计算速度。\n",
    "\n",
    "![](./dt004.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn 中的决策树\n",
    "对于决策树模型，你将使用 scikit-learn 的 Decision Tree Classifier 类。该类提供了定义模型并将模型与数据进行拟合的函数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(x_values, y_values)\n",
    "print(model.predict([ [0.2, 0.8], [0.5, 0.4] ]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 超参数\n",
    "当我们定义模型时，可以指定超参数。在实践中，最常见的超参数包括：\n",
    "\n",
    "max_depth：树中的最大层级数量。\n",
    "\n",
    "min_samples_leaf：叶子允许的最低样本数量。\n",
    "\n",
    "min_samples_split：拆分内部节点所需的最低样本数量。\n",
    "\n",
    "max_features：寻找最佳拆分方法时要考虑的特征数量。\n",
    "\n",
    "例如，在此例中，我们定义了一个模型：树的最大深度 max_depth 为7，每个叶子的最低元素数量 min_samples_leaf 是 10。\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth = 7, min_samples_leaf = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建决策树步骤：\n",
    "\n",
    "## 1.构建决策树模型\n",
    "\n",
    "使用 scikit-learn 的 DecisionTree 类构建决策树分类模型，并将其赋值给变量 model。\n",
    "\n",
    "## 2.将模型与数据进行拟合\n",
    "\n",
    "你不需要指定任何超参数，因为默认的超参数将以 100% 的准确率拟合数据。\n",
    "\n",
    "但是，建议你实验这些超参数，例如 max_depth 和 min_samples_leaf，并尝试找到最简单的潜在模型，即最不太可能过拟合的模型！\n",
    "\n",
    "## 3.使用模型进行预测\n",
    "\n",
    "预测训练集的标签，并将此列表赋值给变量 y_pred。\n",
    "\n",
    "## 4.计算模型的准确率\n",
    "\n",
    "为此，使用 sklearn 函数 accuracy_score。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码实现:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the data.\n",
    "data = np.asarray(pd.read_csv('data.csv', header=None))\n",
    "# Assign the features to the variable X, and the labels to the variable y. \n",
    "X = data[:,0:2]\n",
    "y = data[:,2]\n",
    "\n",
    "# TODO: Create the decision tree model and assign it to the variable model.\n",
    "# You won't need to, but if you'd like, play with hyperparameters such\n",
    "# as max_depth and min_samples_leaf and see what they do to the decision\n",
    "# boundary.\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# TODO: Fit the model.\n",
    "model.fit(X,y)\n",
    "# TODO: Make predictions. Store them in the variable y_pred.\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# TODO: Calculate the accuracy and assign it to the variable acc.\n",
    "acc = accuracy_score(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 小结：\n",
    "\n",
    "决策树的一个重要任务是为了理解数据中所蕴含的知识信息，因此决策树可以使用不熟悉的数据集合，并从中提取一系列规则。\n",
    "\n",
    "这个机器根据数据集创建规则的过程，就是机器学习过程。\n",
    "\n",
    "专家系统中，经常使用决策树，而且决策树给出结果往往可以匹配当前领域具有几十年工作经验的人类专家。\n",
    "\n",
    "优点：计算复杂度不高，输出结果易于理解，对中间值的却是不敏感，可以处理不相关特征数据；\n",
    "\n",
    "缺点：可能会产生过度匹配问题；\n",
    "\n",
    "适用数据类型：数值型和标称型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITTensorFlow",
   "language": "python",
   "name": "intrototensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
