{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Mission\n",
    "\n",
    "在本课中，你了解了许多模型性能的评估技术。这个notebook的目标是为你提供一些与分类特别相关的指标的练习。基于此目标，我们将再次查看之前课程中的垃圾邮件数据集。\n",
    "\n",
    "首先，运行下面的单元格，准备数据并实例化多个不同的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# Import our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "import tests as t\n",
    "\n",
    "# Read in our dataset\n",
    "df = pd.read_table('smsspamcollection/SMSSpamCollection',\n",
    "                   sep='\\t', \n",
    "                   header=None, \n",
    "                   names=['label', 'sms_message'])\n",
    "\n",
    "# Fix our response value\n",
    "df['label'] = df.label.map({'ham':0, 'spam':1})\n",
    "\n",
    "# Split our dataset into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['sms_message'], \n",
    "                                                    df['label'], \n",
    "                                                    random_state=1)\n",
    "\n",
    "# Instantiate the CountVectorizer method\n",
    "count_vector = CountVectorizer()\n",
    "\n",
    "# Fit the training data and then return the matrix\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "\n",
    "# Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
    "testing_data = count_vector.transform(X_test)\n",
    "\n",
    "# Instantiate a number of our models\n",
    "naive_bayes = MultinomialNB()\n",
    "bag_mod = BaggingClassifier(n_estimators=200)\n",
    "rf_mod = RandomForestClassifier(n_estimators=200)\n",
    "ada_mod = AdaBoostClassifier(n_estimators=300, learning_rate=0.2)\n",
    "svm_mod = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **步骤 1**：现在，用适当的数据对上述的每个模型进行拟合。回答以下问题以确保你正确拟合模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit each of the 4 models\n",
    "# This might take some time to run\n",
    "naive_bayes.fit(training_data, y_train)\n",
    "bag_mod.fit(training_data, y_train)\n",
    "rf_mod.fit(training_data, y_train)\n",
    "ada_mod.fit(training_data, y_train)\n",
    "svm_mod.fit(training_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The models you fit above were fit on which data?\n",
    "\n",
    "a = 'X_train'\n",
    "b = 'X_test'\n",
    "c = 'y_train'\n",
    "d = 'y_test'\n",
    "e = 'training_data'\n",
    "f = 'testing_data'\n",
    "\n",
    "# Change models_fit_on to only contain the correct string names\n",
    "# of values that you oassed to the above models\n",
    "\n",
    "models_fit_on = {a, b, c, d, e, f} # update this to only contain correct letters\n",
    "\n",
    "# Checks your solution - don't change this\n",
    "t.test_one(models_fit_on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **步骤 2**：现在用你的模型对新数据进行预测，这将能检验模型的泛化能力。然后用正确的字符串给下面单元格中的集合对象赋值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using each of your models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which data was used in the predict method to see how well your\n",
    "# model would work on new data?\n",
    "\n",
    "a = 'X_train'\n",
    "b = 'X_test'\n",
    "c = 'y_train'\n",
    "d = 'y_test'\n",
    "e = 'training_data'\n",
    "f = 'testing_data'\n",
    "\n",
    "# Change models_predict_on to only contain the correct string names\n",
    "# of values that you oassed to the above models\n",
    "\n",
    "models_predict_on = {a, b, c, d, e, f} # update this to only contain correct letters\n",
    "\n",
    "# Checks your solution - don't change this\n",
    "t.test_two(models_predict_on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在你已经设置好了所有的预测，让我们进入本课的主题 - 评估模型的性能。首先，我们将关注如何计算单个模型的指标，然后在本notebook的最后部分，你将要根据特定指标选择最合适的模型。\n",
    "\n",
    "你将编写函数来计算很多指标，然后将其与用sklearn库计算的结果做比较。这将有助于你建立关于如何计算每个指标的直觉。\n",
    "\n",
    "> **步骤 3**：请运行下面的单元格中的示例，以了解如何解决接下来的问题。请填写下面的函数来计算准确度，然后将你的答案与内置答案进行比较，以确保答案正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy is the total correct divided by the total to predict\n",
    "def accuracy(actual, preds):\n",
    "    '''\n",
    "    INPUT\n",
    "    preds - predictions as a numpy array or pandas series\n",
    "    actual - actual values as a numpy array or pandas series\n",
    "    \n",
    "    OUTPUT:\n",
    "    returns the accuracy as a float\n",
    "    '''\n",
    "    return np.sum(preds == actual)/len(actual)\n",
    "\n",
    "\n",
    "print(accuracy(y_test, preds_nb))\n",
    "print(accuracy_score(y_test, preds_nb))\n",
    "print(\"Since these match, we correctly calculated our metric!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **步骤4**：请填写下面的函数来计算精度，然后将你的答案与内置答案进行比较，以确保答案正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision is the true positives over the predicted positive values\n",
    "def precision(actual, preds):\n",
    "    '''\n",
    "    INPUT\n",
    "    (assumes positive = 1 and negative = 0)\n",
    "    preds - predictions as a numpy array or pandas series \n",
    "    actual - actual values as a numpy array or pandas series\n",
    "    \n",
    "    OUTPUT:\n",
    "    returns the precision as a float\n",
    "    '''\n",
    "    \n",
    "    return None # calculate precision here\n",
    "\n",
    "\n",
    "print(precision(y_test, preds_nb))\n",
    "print(precision_score(y_test, preds_nb))\n",
    "print(\"If the above match, you got it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **步骤5**：请填写下面的函数来计算召回率，然后将你的答案与内置答案进行比较，以确保答案正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall is true positives over all actual positive values\n",
    "def recall(actual, preds):\n",
    "    '''\n",
    "    INPUT\n",
    "    preds - predictions as a numpy array or pandas series\n",
    "    actual - actual values as a numpy array or pandas series\n",
    "    \n",
    "    OUTPUT:\n",
    "    returns the recall as a float\n",
    "    '''\n",
    "\n",
    "    return None # calculate recall here\n",
    "\n",
    "\n",
    "print(recall(y_test, preds_nb))\n",
    "print(recall_score(y_test, preds_nb))\n",
    "print(\"If the above match, you got it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **步骤6**：请填写下面的函数来计算f1 分数，然后将你的答案与内置答案进行比较，以确保答案正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_score is 2*(precision*recall)/(precision+recall))\n",
    "def f1(preds, actual):\n",
    "    '''\n",
    "    INPUT\n",
    "    preds - predictions as a numpy array or pandas series\n",
    "    actual - actual values as a numpy array or pandas series\n",
    "    \n",
    "    OUTPUT:\n",
    "    returns the f1score as a float\n",
    "    '''\n",
    "    \n",
    "    return None # calculate f1-score here\n",
    "\n",
    "\n",
    "print(f1(y_test, preds_nb))\n",
    "print(f1_score(y_test, preds_nb))\n",
    "print(\"If the above match, you got it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **步骤7**：现在你已经计算了许多不同的指标，让我们看一下如何从中选择一个合适的指标。请用将下列指标和字典中标识其适用情况的语句进行配对。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the letter of the most appropriate metric to each statement\n",
    "# in the dictionary\n",
    "a = \"recall\"\n",
    "b = \"precision\"\n",
    "c = \"accuracy\"\n",
    "d = 'f1-score'\n",
    "\n",
    "\n",
    "seven_sol = {\n",
    "'We have imbalanced classes, which metric do we definitely not want to use?': None # letter here,\n",
    "'We really want to make sure the positive cases are all caught even if that means we identify some negatives as positives': None # letter here,    \n",
    "'When we identify something as positive, we want to be sure it is truly positive': None # letter here, \n",
    "'We care equally about identifying positive and negative cases': None # letter here    \n",
    "}\n",
    "\n",
    "t.sol_seven(seven_sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **步骤8**：根据你现在对这些指标的理解，将模型与下面字典中的语句配对。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the answers you found to the previous questiona, then match the model that did best for each metric\n",
    "a = \"naive-bayes\"\n",
    "b = \"bagging\"\n",
    "c = \"random-forest\"\n",
    "d = 'ada-boost'\n",
    "e = \"svm\"\n",
    "\n",
    "\n",
    "eight_sol = {\n",
    "'We have imbalanced classes, which metric do we definitely not want to use?': None # letter here,\n",
    "'We really want to make sure the positive cases are all caught even if that means we identify some negatives as positives': None # letter here,    \n",
    "'When we identify something as positive, we want to be sure it is truly positive': None # letter here, \n",
    "'We care equally about identifying positive and negative cases': None # letter here  \n",
    "}\n",
    "\n",
    "t.sol_eight(eight_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cells for work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you get stuck, also notice there is a solution available by hitting the orange button in the top left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作为本练习的最后一步，让我们看看最后三个指标：f-beta 分数、 ROC 曲线和 AUC。\n",
    "\n",
    "**f-beta 分数：** 如果你更关注精度，你应该让beta值接近零。如果你更关注召回率，你应该让beta值趋向无穷大。 \n",
    "\n",
    "> **步骤9**：使用 fbeta_score 函数与使用 sklearn 库的其他指标类似，但你还要设置参数 beta 来控制精度和召回率的权重。请填写下面空格的代码，以表明你可以使用 sklearn 库的 [fbeta_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html) 函数来重现上面的 f1-score 函数的结果。未来你可能会尝试使用不同的权重，[这篇文章](http://mlwiki.org/index.php/Precision_and_Recall)很好地解释了如何根据不同的情况调整 beta。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fbeta_score\n",
    "\n",
    "\n",
    "# Show that you can produce the same f1_score results using fbeta_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **步骤10**：用 Python 生成 ROC 曲线是一个非常独立的过程。我编写了下面的函数来帮助完成这个过程，也可以方便你将来使用。请尝试使用你在上面创建的其他分类器，把它们和下面的随机森林模型做比较，看有什么不同。\n",
    "\n",
    "运行下面的单元格以构建 ROC 曲线，找出随机林模型的 AUC。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating auc and roc\n",
    "\n",
    "def build_roc_auc(model, X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    INPUT:\n",
    "    model - an sklearn instantiated model\n",
    "    X_train - the training data\n",
    "    y_train - the training response values (must be categorical)\n",
    "    X_test - the test data\n",
    "    y_test - the test response values (must be categorical)\n",
    "    OUTPUT:\n",
    "    auc - returns auc as a float\n",
    "    prints the roc curve\n",
    "    '''\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from itertools import cycle\n",
    "    from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "    from scipy import interp\n",
    "    \n",
    "    y_preds = model.fit(X_train, y_train).predict_proba(X_test)\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(len(y_test)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test, y_preds[:, 1])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_preds[:, 1].ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "             lw=2, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.show()\n",
    "    \n",
    "    return roc_auc_score(y_test, np.round(y_preds[:, 1]))\n",
    "    \n",
    "    \n",
    "# Finding roc and auc for the random forest model    \n",
    "build_roc_auc(rf_mod, training_data, testing_data, y_train, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn here - choose another classifier to see how it compares\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
